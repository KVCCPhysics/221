<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-08-14 Wed 15:31 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Lab Resources: Video Processing</title>
<meta name="author" content="Patrick Malsom" />
<meta name="generator" content="Org Mode" />
<style type="text/css">
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
</head>
<body>
<div id="preamble" class="status">
<style type="text/css">body{ max-width:800px; margin: auto;font-family: LatoWeb, "Lato Extended", Lato, "Helvetica Neue", Helvetica, Arial, sans-serif;}table.center{margin-left:auto; margin-right:auto;}</style>
</div>
<div id="content" class="content">
<h1 class="title">Lab Resources: Video Processing</h1>
<p>
This page outline steps to take a video recorded on a camera or smartphone and create a short video of the event in a file type which can be used by ImageJ. This guide only discusses the video processing to prepare for use in ImageJ (mjpeg or avi format). Please see <a href="./LabResources-ImageJ.html">Data Extraction with ImageJ</a> for help with the ImageJ Program.
</p>

<p>
You will need to install Handbrake and ImageJ to complete this guide. This is all <i>free and open source software</i>:
</p>

<ul class="org-ul">
<li><b>Handbrake</b> Video Transcoder. Used to cut out a piece of a video based on time or frame number and encode the video in h264 format. <a href="https://handbrake.fr/">https://handbrake.fr/</a></li>
<li><b>ImageJ</b> Image processing and scripting software. ImageJ is widely used in biology and astronomy research (analyzing microscope and telescope images, etc) and is funded by the US Government (National institute of Health). <a href="https://imagej.nih.gov/ij/">https://imagej.nih.gov/ij/</a>

<ul class="org-ul">
<li><b>VLC or SMPlayer (optional)</b> media player. Use: Allows you to move forward (and backward with SMPlayer) a single frame.<a href="https://www.videolan.org/vlc/">https://www.videolan.org/vlc/</a>  <a href="https://www.smplayer.info/en/info">https://www.smplayer.info/en/info</a></li>
</ul></li>

<li>This guide will also use <b>ffmpeg</b>, but you do not need to install on your personal computer as it is included with Google Cocalc. Note: ffmpeg is messy to install on Windows, please use the Jupyter interface instead (outlined below).</li>
</ul>
<div id="outline-container-org0d1a184" class="outline-2">
<h2 id="org0d1a184">Step 1: Recording the event</h2>
<div class="outline-text-2" id="text-org0d1a184">
<p>
A very useful technique for measurement of mechanical systems is simply to record the motion using a camera. Cameras have become very good at taking somewhat high speed video (120 FPS is common, with some phones even being able to record at 1000FPS), and very interesting phenomena can be investigated using the footage.
</p>

<p>
Remember to double check the camera is actually recording before starting the experiment. It is good practice to start recording the video at least a few seconds before and after the actual event. The event will be cut from the longer video later.
</p>

<p>
Some advice:
</p>
<ul class="org-ul">
<li>Remember to place reference measurement devices (a meter stick for example) in the frame of the video. Two references should be used if the motion is two dimensional.</li>
<li>Set the shutter speed to double the frame rate (240 FPS -&gt; 1/480 second shutter speed)</li>
<li>Film the event in very bright conditions (direct sunlight), so you can lower the shutter speed on very high frame rates. Avoid using LED lights, as the PWM will create variance in brigness of the individual frames.</li>
<li>Do not record for a long period of time. High speed video will create large files very quickly. A 2 minute video at 240 FPS creates a 1GB file with h264 compression.</li>
</ul>
</div>
</div>
<div id="outline-container-org7e083d9" class="outline-2">
<h2 id="org7e083d9">Step 2: Using Handbrake to trim the video</h2>
<div class="outline-text-2" id="text-org7e083d9">
<p>
After you record the raw footage, move the video file to a computer. Use a media player to find the time range which includes the relevant parts of the motion. Be sure to get all of the motion you think is important, add a second to the beginning if you are unsure (you can further trim the video in step 2). Then use Handbreak to cut the important motion our of the raw video:
</p>

<ol class="org-ol">
<li>Open file -&gt; select the original (long) video file.</li>
<li>Select &ldquo;Preset&rdquo;: Fast 1080p30.</li>
<li>Select &ldquo;Range&rdquo;: Seconds (input your time range).</li>
<li>Select &ldquo;Framerate&rdquo;: Same as source (under the video tab).</li>
<li>Select &ldquo;Browse&rdquo; in the bottom right to save the new short video.</li>
<li>Click &ldquo;Start Encode&rdquo; to create the shortened video of the event.</li>
</ol>

<p>
Please review the output video to see if the entire event is captured.
</p>

<p>
<b>Result from this step:</b> A short M4V video file (a couple seconds) showing the entire event. I will call this file &ldquo;event.m4v&rdquo;
</p>
</div>
</div>
<div id="outline-container-org93c3f45" class="outline-2">
<h2 id="org93c3f45">Step 2: Trim the video</h2>
<div class="outline-text-2" id="text-org93c3f45">
<p>
This is an optional but encouraged step. Here, you take the rough trimmed video (<i>event.m4v</i>) and isolate only the frames which you find important. To accomplish this, I find it easiest to add the frame number to the video with ffmpeg, and then use handbrake to reprocess the video to create a new video file. This will help keep your file size to a minimum in the later analysis and let you focus only on the important part of the motion.
</p>

<ol class="org-ol">
<li>Create a new notebook in <a href="https://colab.research.google.com">Google Colaboratory</a> named &ldquo;TrimVideo.ipynb&rdquo;.</li>
<li>Upload the rough cut <i>event.m4v</i> to Colab.</li>
<li><p>
Add frame numbers to the video with ffmpeg
</p>
<div class="org-src-container">
<pre class="src src-nil">   !ffmpeg -i event.m4v -vf "drawtext=fontfile=Arial.ttf: text='%{pts\:flt} \#%{frame_num}': start_number=1: x=500: y=900: fontcolor=white: fontsize=60: " -y -c:a copy event_frames.m4v
</pre>
</div></li>
<li>Download the newly created <i>event<sub>frames.m4v</sub></i> file to your computer.</li>
<li>View this file with a media player and identify which frames you want to keep. In VLC Media Player, click View-&gt;Advanced Controls to show a button for single frame advance (looks similar to the play button). In SMPlayer, simply press the comma and period button to move frames.</li>
<li>Use Handbrake to trim the original file (<i>event.m4v</i>) based on frame number. Follow the instructions above (Step 1) to encode the new file, which I will call &ldquo;<i>event<sub>trim.m4v</sub></i>&rdquo;, except select &ldquo;Range: Frame&rdquo; for the third step. Be sure to load the original file (without frame numbers) into handbrake, as you will reprint the frame numbers with the new trimmed video in the next step.</li>
</ol>

<p>
<b>Result from this step:</b> A short M4V video file (a couple seconds) showing the event. This file is now trimmed to the correct starting and ending frame. I will call this file &ldquo;event<sub>trim.m4v</sub>&rdquo;.
</p>
</div>
</div>
<div id="outline-container-org3da191d" class="outline-2">
<h2 id="org3da191d">Step 3: Convert to mjpeg</h2>
<div class="outline-text-2" id="text-org3da191d">
<p>
In this step, you will take your raw video and cut out the important parts in preparation for further analysis. ImageJ requires a somewhat primitive video format called mjpeg, which is essentially a series of jpeg images all glued together. This file format will create files which are much larger than a normal mp4 or m4v file (format which youtube uses). You will be uploading your file to Google Colab and doing the video processing using a command line transcoding software called ffmpeg.
</p>

<ol class="org-ol">
<li>Open a new notebook in <a href="https://colab.research.google.com">Google Colaboratory</a> named &ldquo;TrimVideo.ipynb&rdquo;.</li>
<li>Upload the trimmed video <i>event<sub>trim.m4v</sub></i> to colab.</li>
<li><p>
Add frame numbers to the video with ffmpeg and convert to an mjpeg (avi) format (Be careful, this makes LARGE FILES!):
</p>
<div class="org-src-container">
<pre class="src src-nil">   !ffmpeg -i event_trim.m4v -vf "drawtext=fontfile=Arial.ttf: text='t\=%{pts\:flt}s    Frame\:%{frame_num}': start_number=0: x=600: y=900: fontcolor=white: fontsize=60, crop=w=1920:h=1080:x=0:y=0" -an -vcodec mjpeg -y -q:v 4 event_imagej.avi
</pre>
</div>

<p>
Options for ffmpeg:
</p>
<ul class="org-ul">
<li>drawtext is used to insert text on top of the frames. Options for text location, color and size are shown.</li>
<li>drawtext is used to crop area Example: crop to size 100x100 at position (12,34). crop=w=100:h=100:x=12:y=34</li>
<li>video codec must be specified with &ldquo;-vcodec mjpeg&rdquo; for use with ImageJ</li>
<li>audio is dropped with the -an flag</li>
<li>image quality is specified with the -q:v flag. Highest quality and largest size is 2, lowest quality and smallest size is 31 (linear compression ratio).</li>
</ul></li>
<li>download the new &ldquo;/event<sub>imagej.avi</sub>&rdquo; file.</li>
</ol>

<p>
Success! Now you should be left with a clip of your event which can be imported into ImageJ!
</p>
</div>
</div>
<div id="outline-container-org98a5be7" class="outline-2">
<h2 id="org98a5be7">Step 4: Opening video in ImageJ</h2>
<div class="outline-text-2" id="text-org98a5be7">
<ol class="org-ol">
<li>Download ImageJ and extract the folder. Double click on the ImageJ applicaiton to start. You should see a horizontal bar with a bunch of buttons and no words&#x2026;</li>
<li>Click File-&gt;Open and select the mjpeg file. Please be sure to select the mjpeg file, as ImageJ cannot open M4V or MP4 file types.</li>
<li><p>
A window named &ldquo;AVI Reader&rdquo; should open. Select OK and your video should be displayed.
</p>

<p>
Now we can move on to analysis: <a href="./LabResources-ImageJ.html">Lab Resources - Data Extraction with ImageJ</a>
</p></li>
</ol>
</div>
</div>
</div>
</body>
</html>
